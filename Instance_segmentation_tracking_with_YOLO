# Instance segmentation and tracking using YOLOv8  
import cv2
from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors
from collections import defaultdict

track_history = defaultdict(lambda: [])

model = YOLO("yolov8n-seg.pt")   # segmentation model
cap = cv2.VideoCapture("") # input video to be analysed
width, height, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

output_video = cv2.VideoWriter('instance-segmentation-object-tracking.mp4', cv2.VideoWriter_fourcc(*'MP4V'), fps, (w, h))

while True:
    ret, individual_frame = cap.read()
    if not ret:
        print("Video frame is empty / video processing has been successfully completed.")
        break

    annotator = Annotator(individual_frame, line_width=2)

    results = model.track(individual_frame, persist=True)

    if results[0].boxes.id is not None and results[0].masks is not None:
        masks = results[0].masks.xy
        tracking_ids = results[0].boxes.id.int().cpu().tolist()

        for mask, track_id in zip(masks, tracking_ids):
            annotator.seg_bbox(mask=mask,
                               mask_color=colors(track_id, True),
                               track_label=str(track_id))

    output_video.write(individual_frame)
    # cv2.imshow("instance-segmentation-object-tracking", im0)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

output_video.release()
cap.release()
cv2.destroyAllWindows()
